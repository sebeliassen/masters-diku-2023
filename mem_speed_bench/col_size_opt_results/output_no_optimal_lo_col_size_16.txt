
===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please run

python -m bitsandbytes

 and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
bin /opt/conda/envs/exact/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda111.so
CUDA SETUP: CUDA runtime path found: /opt/conda/envs/exact/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 7.5
CUDA SETUP: Detected CUDA version 111
CUDA SETUP: Loading binary /opt/conda/envs/exact/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda111.so...
==============================Store activation in INT2==============================
use qmodule: True
kept frac: 0.125
amp mode: False
use the custom loss function
Use GPU 0 for training
clipping grad norm: 0.5
convert the model
QModule(
  (model): SAGE(
    (dropout): QDropout()
    (activation): QReLU()
    (convs): ModuleList(
      (0): QSAGEConv(128, 128)
      (1): QSAGEConv(128, 128)
      (2): QSAGEConv(128, 40)
    )
    (bns): ModuleList(
      (0): QBatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): QBatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
========== Model and Optimizer Only ===========
allocated: 0.30 MB
reserved:  2.00 MB
========== Load data to GPU ===========
allocated: 162.31 MB
reserved:  180.00 MB
========== Before Backward ===========
allocated: 206.65 MB
reserved:  566.00 MB
max allocated mem (MB): 529.916015625
Total Mem: 206.65 MB	Data Mem: 162.01 MB	Act Mem: 30.47 MB
========== After Backward ===========
allocated: 163.19 MB
reserved:  588.00 MB
Total Mem: 207.53 MB	Data Mem: 162.01 MB	Act Mem: 30.47 MB
max allocated mem (MB): 541.99560546875
Save exp results to mem_results.json
epoch/s: 8.567591672765579
CarbonTracker: The following components were found: GPU with device(s) Tesla T4.
CarbonTracker: 
Actual consumption for 1 epoch(s):
	Time:	0:00:00
	Energy:	0.000002 kWh
	CO2eq:	0.000735 g
	This is equivalent to:
	0.000007 km travelled by car
CarbonTracker: 
Predicted consumption for 100 epoch(s):
	Time:	0:00:11
	Energy:	0.000208 kWh
	CO2eq:	0.073473 g
	This is equivalent to:
	0.000683 km travelled by car
CarbonTracker: Finished monitoring.

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please run

python -m bitsandbytes

 and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
bin /opt/conda/envs/exact/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda111.so
CUDA SETUP: CUDA runtime path found: /opt/conda/envs/exact/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 7.5
CUDA SETUP: Detected CUDA version 111
CUDA SETUP: Loading binary /opt/conda/envs/exact/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda111.so...
==============================Store activation in INT2==============================
use qmodule: True
kept frac: 0.125
amp mode: False
use the custom loss function
Use GPU 0 for training
clipping grad norm: 0.5
convert the model
QModule(
  (model): SAGE(
    (dropout): QDropout()
    (activation): QReLU()
    (convs): ModuleList(
      (0): QSAGEConv(128, 128)
      (1): QSAGEConv(128, 128)
      (2): QSAGEConv(128, 40)
    )
    (bns): ModuleList(
      (0): QBatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): QBatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
========== Model and Optimizer Only ===========
allocated: 0.30 MB
reserved:  2.00 MB
========== Load data to GPU ===========
allocated: 162.31 MB
reserved:  180.00 MB
========== Before Backward ===========
allocated: 206.65 MB
reserved:  566.00 MB
max allocated mem (MB): 529.916015625
Total Mem: 206.65 MB	Data Mem: 162.01 MB	Act Mem: 30.47 MB
========== After Backward ===========
allocated: 163.19 MB
reserved:  588.00 MB
Total Mem: 207.53 MB	Data Mem: 162.01 MB	Act Mem: 30.47 MB
max allocated mem (MB): 541.99560546875
Save exp results to mem_results.json
epoch/s: 8.573891860846949
CarbonTracker: The following components were found: GPU with device(s) Tesla T4.
CarbonTracker: 
Actual consumption for 1 epoch(s):
	Time:	0:00:00
	Energy:	0.000002 kWh
	CO2eq:	0.000731 g
	This is equivalent to:
	0.000007 km travelled by car
CarbonTracker: 
Predicted consumption for 100 epoch(s):
	Time:	0:00:11
	Energy:	0.000207 kWh
	CO2eq:	0.073121 g
	This is equivalent to:
	0.000680 km travelled by car
CarbonTracker: Finished monitoring.

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please run

python -m bitsandbytes

 and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
bin /opt/conda/envs/exact/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda111.so
CUDA SETUP: CUDA runtime path found: /opt/conda/envs/exact/lib/libcudart.so.11.0
CUDA SETUP: Highest compute capability among GPUs detected: 7.5
CUDA SETUP: Detected CUDA version 111
CUDA SETUP: Loading binary /opt/conda/envs/exact/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda111.so...
==============================Store activation in INT2==============================
use qmodule: True
kept frac: 0.125
amp mode: False
use the custom loss function
Use GPU 0 for training
clipping grad norm: 0.5
convert the model
QModule(
  (model): SAGE(
    (dropout): QDropout()
    (activation): QReLU()
    (convs): ModuleList(
      (0): QSAGEConv(128, 128)
      (1): QSAGEConv(128, 128)
      (2): QSAGEConv(128, 40)
    )
    (bns): ModuleList(
      (0): QBatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): QBatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
========== Model and Optimizer Only ===========
allocated: 0.30 MB
reserved:  2.00 MB
========== Load data to GPU ===========
allocated: 162.31 MB
reserved:  180.00 MB
========== Before Backward ===========
allocated: 206.65 MB
reserved:  566.00 MB
max allocated mem (MB): 529.916015625
Total Mem: 206.65 MB	Data Mem: 162.01 MB	Act Mem: 30.47 MB
========== After Backward ===========
allocated: 163.19 MB
reserved:  588.00 MB
Total Mem: 207.53 MB	Data Mem: 162.01 MB	Act Mem: 30.47 MB
max allocated mem (MB): 541.99560546875
Save exp results to mem_results.json
epoch/s: 8.570026724326738
CarbonTracker: The following components were found: GPU with device(s) Tesla T4.
CarbonTracker: 
Actual consumption for 1 epoch(s):
	Time:	0:00:00
	Energy:	0.000002 kWh
	CO2eq:	0.000683 g
	This is equivalent to:
	0.000006 km travelled by car
CarbonTracker: 
Predicted consumption for 100 epoch(s):
	Time:	0:00:10
	Energy:	0.000194 kWh
	CO2eq:	0.068291 g
	This is equivalent to:
	0.000635 km travelled by car
CarbonTracker: Finished monitoring.

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please run

python -m bitsandbytes

 and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
bin /opt/conda/envs/exact/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda111.so
CUDA SETUP: CUDA runtime path found: /opt/conda/envs/exact/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 7.5
CUDA SETUP: Detected CUDA version 111
CUDA SETUP: Loading binary /opt/conda/envs/exact/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda111.so...
==============================Store activation in INT2==============================
use qmodule: True
kept frac: 0.125
amp mode: False
use the custom loss function
Use GPU 0 for training
clipping grad norm: 0.5
convert the model
QModule(
  (model): SAGE(
    (dropout): QDropout()
    (activation): QReLU()
    (convs): ModuleList(
      (0): QSAGEConv(128, 128)
      (1): QSAGEConv(128, 128)
      (2): QSAGEConv(128, 40)
    )
    (bns): ModuleList(
      (0): QBatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): QBatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
========== Model and Optimizer Only ===========
allocated: 0.30 MB
reserved:  2.00 MB
========== Load data to GPU ===========
allocated: 162.31 MB
reserved:  180.00 MB
========== Before Backward ===========
allocated: 206.65 MB
reserved:  566.00 MB
max allocated mem (MB): 529.916015625
Total Mem: 206.65 MB	Data Mem: 162.01 MB	Act Mem: 30.47 MB
========== After Backward ===========
allocated: 163.19 MB
reserved:  588.00 MB
Total Mem: 207.53 MB	Data Mem: 162.01 MB	Act Mem: 30.47 MB
max allocated mem (MB): 541.99560546875
Save exp results to mem_results.json
epoch/s: 8.582878361885058
CarbonTracker: The following components were found: GPU with device(s) Tesla T4.
CarbonTracker: 
Actual consumption for 1 epoch(s):
	Time:	0:00:00
	Energy:	0.000004 kWh
	CO2eq:	0.001430 g
	This is equivalent to:
	0.000013 km travelled by car
CarbonTracker: 
Predicted consumption for 100 epoch(s):
	Time:	0:00:13
	Energy:	0.000406 kWh
	CO2eq:	0.143038 g
	This is equivalent to:
	0.001331 km travelled by car
CarbonTracker: Finished monitoring.

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please run

python -m bitsandbytes

 and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
bin /opt/conda/envs/exact/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda111.so
CUDA SETUP: CUDA runtime path found: /opt/conda/envs/exact/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 7.5
CUDA SETUP: Detected CUDA version 111
CUDA SETUP: Loading binary /opt/conda/envs/exact/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda111.so...
==============================Store activation in INT2==============================
use qmodule: True
kept frac: 0.125
amp mode: False
use the custom loss function
Use GPU 0 for training
clipping grad norm: 0.5
convert the model
QModule(
  (model): SAGE(
    (dropout): QDropout()
    (activation): QReLU()
    (convs): ModuleList(
      (0): QSAGEConv(128, 128)
      (1): QSAGEConv(128, 128)
      (2): QSAGEConv(128, 40)
    )
    (bns): ModuleList(
      (0): QBatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): QBatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
========== Model and Optimizer Only ===========
allocated: 0.30 MB
reserved:  2.00 MB
========== Load data to GPU ===========
allocated: 162.31 MB
reserved:  180.00 MB
========== Before Backward ===========
allocated: 206.65 MB
reserved:  566.00 MB
max allocated mem (MB): 529.916015625
Total Mem: 206.65 MB	Data Mem: 162.01 MB	Act Mem: 30.47 MB
========== After Backward ===========
allocated: 163.19 MB
reserved:  588.00 MB
Total Mem: 207.53 MB	Data Mem: 162.01 MB	Act Mem: 30.47 MB
max allocated mem (MB): 541.99560546875
Save exp results to mem_results.json
epoch/s: 8.72305389909614
CarbonTracker: The following components were found: GPU with device(s) Tesla T4.
CarbonTracker: 
Actual consumption for 1 epoch(s):
	Time:	0:00:00
	Energy:	0.000003 kWh
	CO2eq:	0.001023 g
	This is equivalent to:
	0.000010 km travelled by car
CarbonTracker: 
Predicted consumption for 100 epoch(s):
	Time:	0:00:09
	Energy:	0.000290 kWh
	CO2eq:	0.102333 g
	This is equivalent to:
	0.000952 km travelled by car
CarbonTracker: Finished monitoring.
